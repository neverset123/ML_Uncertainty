## loss
donot present squared loss to stackholder as it has different unit to the measurement.

## activation
ReLu activation will results in shape boundary edges

## dropout at train and test phase

## BNN
dropout rate is better at 0.2 than at 0.5

## prunning
dropping connection betwwen neutrons in previous layer and current layer

## uncertainty estimation
### MC Dropout

### DropConnect

